<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>~stesie's musings</title><link>https://stefansiegl.de/</link><description>Recent content on ~stesie's musings</description><generator>Hugo -- 0.123.7</generator><language>en-us</language><copyright>2025 Stefan Siegl ¬∑ all content is CC-BY-SA ¬∑ Terms of Service</copyright><lastBuildDate>Thu, 19 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://stefansiegl.de/feed.xml" rel="self" type="application/rss+xml"/><item><title>Dependency Inversion for Camunda Tasks</title><link>https://stefansiegl.de/2025/06/dependency-inversion-for-camunda-tasks/</link><pubDate>Thu, 19 Jun 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/06/dependency-inversion-for-camunda-tasks/</guid><description>In Camunda Service Tasks can be implemented using so-called delegate expressions, which, in the context of CDI, resolve to @Named annotated beans.
This task class has to implement the JavaDelegate interface, which mandates a method named execute, which receives a single argument with a DelegateExecution instance. However there is the Dependency Inversion Principle (DIP), and this way our business code directly depends on two classes from Camunda. Can&amp;rsquo;t we do better?</description></item><item><title>Building WueRide - Experimenting with LLM-Powered Coding and the Fediverse</title><link>https://stefansiegl.de/2025/03/building-wueride-experimenting-with-llm-powered-coding-and-the-fediverse/</link><pubDate>Sun, 30 Mar 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/03/building-wueride-experimenting-with-llm-powered-coding-and-the-fediverse/</guid><description>A few weeks ago, I came across Harper Reed‚Äôs blog post, My LLM codegen workflow atm, which made the rounds in the developer community. While his approach to using a LLM to collect and refine requirements was interesting, &amp;hellip; what really caught my attention was him mentioning, that he uses Aider to let LLMs modify his code.
So what is Aider? Simply put, Aider is a CLI tool that isn‚Äôt tied to a specific LLM.</description></item><item><title>Wayland Support in IntelliJ</title><link>https://stefansiegl.de/2025/03/wayland-support-in-intellij/</link><pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/03/wayland-support-in-intellij/</guid><description>Today I learned, that IntelliJ has support for Wayland Compositor since version 2024.2, so seems like im rather late to the game.
Simply go to Help &amp;gt; Edit custom VM options and add -Dawt.toolkit.name=WLToolkit.
For me it so far works nicely. And the issue of some overlay windows (like object inspector) not being resizable in Sway &amp;hellip; are just gone. Yay ü•≥</description></item><item><title>Scripting IntelliJ</title><link>https://stefansiegl.de/2025/03/scripting-intellij/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/03/scripting-intellij/</guid><description>Recently I learned, that it&amp;rsquo;s possible to script IntelliJ. I picked up on it while Writing an IntelliJ Plugin for my Coverage Tracker project, aka &amp;ldquo;Undercovered&amp;rdquo;. So there is the IDE scripting console, which comes out-of-the-box. You just open the Action panel and search for IDE Scripting Console, next a tiny popup menu should show, asking for whether it should be Groovy or Kotlin (beta). Right away you can enter some code and evaluate it by pressing Control + Return.</description></item><item><title>Writing an IntelliJ Plugin</title><link>https://stefansiegl.de/2025/03/writing-an-intellij-plugin/</link><pubDate>Tue, 04 Mar 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/03/writing-an-intellij-plugin/</guid><description>In a way, this is the last part of my journey creating a Java (Line) Coverage Analyzer.
This article concentrates on creating an IntelliJ plugin, that adapts it to show the results collected by the analyzer created in Let&amp;rsquo;s create a Coverage Analyzer, Part 4.
To get started, check out JetBrains&amp;rsquo; Developing a Plugin article. With recent IntelliJ versions you need to install the Plugin DevKit first, then create a new Project and select the IDE Plugin Generator.</description></item><item><title>Let's create a Coverage Analyzer, Part 4</title><link>https://stefansiegl.de/2025/03/lets-create-a-coverage-analyzer-part-4/</link><pubDate>Sat, 01 Mar 2025 18:30:00 +0000</pubDate><guid>https://stefansiegl.de/2025/03/lets-create-a-coverage-analyzer-part-4/</guid><description>This is part four of my journey creating a Java (Line) Coverage Analyzer.
This time around we&amp;rsquo;ll test the implementation created in part three and look into details what still goes wrong.
One (simplified) example that crashes the current analyzer implementation is this one:
public class Demo3 { public static void main(final String[] argv) { final Stuff stuff = new Stuff( !getBoolean()); bla(&amp;#34;value: &amp;#34; + stuff.boolValue()); } public static boolean getBoolean() { return true; } private static void bla(final String greeting) { System.</description></item><item><title>Let's create a Coverage Analyzer, Part 3</title><link>https://stefansiegl.de/2025/03/lets-create-a-coverage-analyzer-part-3/</link><pubDate>Sat, 01 Mar 2025 11:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/03/lets-create-a-coverage-analyzer-part-3/</guid><description>This is part three of my journey creating a Java (Line) Coverage Analyzer.
This time around we&amp;rsquo;ll look into improving the very naive implementation created in part two. That one ended in a VerifyError and the message
Expecting a stackmap frame at branch target 41
So what is this branch target, and the stackmap frame that it&amp;rsquo;s suddenly missing? To have an easier time inspecting the Byte Code, let&amp;rsquo;s first create a little CLI version of our instrumentation code.</description></item><item><title>Let's create a Coverage Analyzer, Part 2</title><link>https://stefansiegl.de/2025/02/lets-create-a-coverage-analyzer-part-2/</link><pubDate>Wed, 26 Feb 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/02/lets-create-a-coverage-analyzer-part-2/</guid><description>This is part two of my journey creating a Java (Line) Coverage Analyzer.
Here we&amp;rsquo;ll actually implement the Byte Code Instrumentation, as pointed out in the first part.
Since processing the Byte Code itself, i.e. reading the classes, finding the methods, processing line number information, is in itself a huge task, let&amp;rsquo;s rely on the ASM library for that. After all JaCoCo and Cobertura also rely on that, so this seems to be a valid choice üòÇ</description></item><item><title>Let's create a Coverage Analyzer, Part 1</title><link>https://stefansiegl.de/2025/02/lets-create-a-coverage-analyzer-part-1/</link><pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/02/lets-create-a-coverage-analyzer-part-1/</guid><description>Have you ever wondered what happens when you click on &amp;ldquo;Run with Coverage&amp;rdquo; in IntelliJ? Obviously it&amp;rsquo;s running the tests, but how is it collecting the coverage information?
Let&amp;rsquo;s create a simple Line Coverage Analyzer in and for Java ü•≥
First of all, let&amp;rsquo;s write a simple example program (see GitHub)
package de.brokenpipe.dojo.undercovered.demo; public class Demo { public static void main(final String[] argv) { final String greeting = &amp;#34;Hello World&amp;#34;; bla(greeting); bla(&amp;#34;to the blarg&amp;#34;); } private static void bla(final String greeting) { System.</description></item><item><title>Chromium Site Search</title><link>https://stefansiegl.de/2025/02/chromium-site-search/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/02/chromium-site-search/</guid><description>Pretty likely this is a well-known thing to many ü•±, and to be honest, I also kindof knew that Chromium has some search shortcuts, but I never bothered to learn how to use them. To even add to that, I&amp;rsquo;m even well aware that I quite regularly went to pages like dict.leo.org, and used the search feature there. Or I went to our Jira instance, and used the search feature there, regularly just typing a ticket number.</description></item><item><title>Other LLMs writing a Telegram Bot</title><link>https://stefansiegl.de/2025/02/other-llms-writing-a-telegram-bot/</link><pubDate>Sun, 02 Feb 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/02/other-llms-writing-a-telegram-bot/</guid><description>This is the fourth (and likely last) part in this mini series.
‚ÑπÔ∏è This post belongs to a mini series (I&amp;rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:
In Claude writing a Telegram Bot, 1st try I&amp;rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt In Other LLMs writing a Telegram Bot I quickly try DeepSeek and some more LLMs Since DeepSeek currently is all the rage, obviously I had to prompt it as well.</description></item><item><title>Claude writing a Telegram Bot, 3rd try</title><link>https://stefansiegl.de/2025/02/claude-writing-a-telegram-bot-3rd-try/</link><pubDate>Sat, 01 Feb 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/02/claude-writing-a-telegram-bot-3rd-try/</guid><description>This is the third part of the mini series on writing Telegram bots to read my gas meter using Claude.
‚ÑπÔ∏è This post belongs to a mini series (I&amp;rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:
In Claude writing a Telegram Bot, 1st try I&amp;rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt In Other LLMs writing a Telegram Bot I quickly try DeepSeek and some more LLMs Like in the first round, I will once more show the full dialog I&amp;rsquo;ve used to let it generate the implementation.</description></item><item><title>Audio Journaling</title><link>https://stefansiegl.de/2025/01/audio-journaling/</link><pubDate>Thu, 30 Jan 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/01/audio-journaling/</guid><description>For quite some time now, I&amp;rsquo;ve been using Logseq as my personal knowledge management system. It has been an invaluable tool for organizing my thoughts, projects, and ideas. A few months ago, I decided to take it a step further by incorporating journaling into my daily routine. Each morning and evening, I reflect on how I&amp;rsquo;m feeling, what has moved me, what went well during the day, where I excelled, and where there might be room for improvement.</description></item><item><title>Claude writing a Telegram Bot, 2nd try</title><link>https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-2nd-try/</link><pubDate>Tue, 28 Jan 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-2nd-try/</guid><description>This is the second part of the mini series on writing Telegram bots to read my gas meter using Claude.
‚ÑπÔ∏è This post belongs to a mini series (I&amp;rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:
In Claude writing a Telegram Bot, 1st try I&amp;rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt In Other LLMs writing a Telegram Bot I quickly try DeepSeek and some more LLMs Like in the first round, I will first show the full dialog I&amp;rsquo;ve used to let it generate the implementation.</description></item><item><title>Claude writing a Telegram Bot, 1st try</title><link>https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-1st-try/</link><pubDate>Mon, 27 Jan 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-1st-try/</guid><description>Below you&amp;rsquo;ll find results of my initial try in using Claude to write a Telegram Bot.
‚ÑπÔ∏è This post belongs to a mini series (I&amp;rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:
In Claude writing a Telegram Bot, 1st try I&amp;rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt In Other LLMs writing a Telegram Bot I quickly try DeepSeek and some more LLMs My ultimate goal is to figure out how much gas I need to heat my apartment.</description></item><item><title>Shift Left Testing mit automatischer Anforderungsabdeckung</title><link>https://stefansiegl.de/2025/01/shift-left-testing-mit-automatischer-anforderungsabdeckung/</link><pubDate>Sun, 12 Jan 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/01/shift-left-testing-mit-automatischer-anforderungsabdeckung/</guid><description>Am 29. Juni war ich auf dem wunderbaren 6. SoCraTes Day Franken (gro√üe Empfehlung, falls es eine n√§chste Version geben wird). In der Session ‚ÄûShift Left Testing‚Äú von Felix Tensing beleuchtete er die Herausforderungen und seine L√∂sungsans√§tze im Bereich der Software-Anforderungsabdeckung. Hierbei stellte er sein Konzept vor, das speziell das Problem von inhaltlich veralteten oder unvollst√§ndigen Jira-Tickets adressiert.
Problemstellung Jira-Tickets oder √§hnliche Systeme dienen dazu, Anforderungen und Aufgaben im Entwicklungsprozess festzuhalten.</description></item><item><title>Learning Out Loud</title><link>https://stefansiegl.de/2025/01/learning-out-loud/</link><pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/01/learning-out-loud/</guid><description>Lately, I&amp;rsquo;ve come across the concepts of &amp;ldquo;learning in public&amp;rdquo; and &amp;ldquo;digital gardens.&amp;rdquo; A digital garden is a unique approach to organizing and sharing knowledge in a non-linear and evolving manner. Think of it as a personal wiki where one can cultivate ideas, insights, and resources over time. Unlike traditional blogs or websites that present polished and finalized content, digital gardens focus on capturing the learning process itself, fostering exploration and serendipitous connections between different pieces of information.</description></item><item><title>Switching to Sway - My Journey Back to Linux</title><link>https://stefansiegl.de/2025/01/switching-to-sway/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2025/01/switching-to-sway/</guid><description>I recently switched from i3 to the Sway window manager on Ubuntu Linux 24.04, exploring its flexibility and learning to configure it for my needs. I customized keybindings, set up tools like swayidle and swaylock-effects for screen locking, and used kanshi for monitor management and mako for notifications. While it required more manual effort than GNOME or macOS, the result is a highly personalized and functional setup.</description></item><item><title>Rediscovering Programmer Dvorak</title><link>https://stefansiegl.de/2024/12/rediscovering-programmer-dvorak/</link><pubDate>Sat, 28 Dec 2024 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2024/12/rediscovering-programmer-dvorak/</guid><description>About 15 years ago, I stumbled upon the Programmer Dvorak keyboard layout, which completely changed how I thought about typing. This Christmas, I decided to see if my fingers still remembered the layout, and to my surprise, they did‚Äîbetter than my mind could! The experience reignited my love for customizing tools, and I even set up my current system to bring back the layout, blending nostalgia with practicality.</description></item><item><title>JUnit Parameter Resolvers</title><link>https://stefansiegl.de/2024/12/junit-parameter-resolvers/</link><pubDate>Wed, 11 Dec 2024 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2024/12/junit-parameter-resolvers/</guid><description>Today (err, recently) I learned &amp;hellip; that JUnit&amp;rsquo;s extension API allows for parameter resolvers. These kick in every time you use arguments on a test method, lifecycle method or class constructor. For me, so far, none of these methods ever took an argument. But turns out, it&amp;rsquo;s possible &amp;hellip; and even useful.
They have a primitive example here where they allow a test method to take a random number like so:</description></item><item><title>JUnit Assumptions API</title><link>https://stefansiegl.de/2024/08/junit-assumptions-api/</link><pubDate>Sat, 24 Aug 2024 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2024/08/junit-assumptions-api/</guid><description>Today, I discovered a powerful feature in JUnit: the Assumptions API. This API allows you to define assumptions for your tests. If an assumption isn&amp;rsquo;t met, the test execution is aborted rather than marked as failed. This distinction is crucial in scenarios like conditional test execution in CI pipelines. When a test is skipped due to an unmet assumption, it appears as &amp;ldquo;skipped&amp;rdquo; in the test reports, not as &amp;ldquo;passed&amp;rdquo; or &amp;ldquo;failed.</description></item><item><title>(rb)¬≤ ‚Äì Road Bike Route Bot auf Mastodon</title><link>https://stefansiegl.de/2022/05/rb-road-bike-route-bot-auf-mastodon/</link><pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2022/05/rb-road-bike-route-bot-auf-mastodon/</guid><description>Ein Erfahrungsbericht, weil ich ‚Ä¶
mal wieder was mit Geodaten machen wollte (und mich OpenStreetMap schon eine ganze Weile immer wieder umtreibt)
schon l√§nger dar√ºber nachdenke, wie gut es wohl funktioniert, einen zuf√§lligen Fahrrad-Routenvorschlag nach eigenem Gusto zu erzeugen
schon l√§nger im Fediverse (Mastodon) bin und w√§hrend des Alle-Verlassen-Twitter-Hypes einen Bot zu bauen nahe liegt
Also los geht‚Äôs. How hard can it be?
Zun√§chst soll nicht unerw√§hnt bleiben, dass Dienste wie Strava erlauben, eine zuf√§llige Route zu erzeugen; meinen Geschmack treffen die Ergebnisse jedoch eher selten.</description></item><item><title>comparing the incomparible -</title><link>https://stefansiegl.de/2016/11/comparing-the-incomparible/</link><pubDate>Sun, 20 Nov 2016 00:00:00 +0000</pubDate><guid>https://stefansiegl.de/2016/11/comparing-the-incomparible/</guid><description>Lucky me, living in the metropolitan area of Nuremberg, &amp;hellip; this year I attended three different developer-oriented open spaces hosted within one hour driving range from home.
devops camp¬†in Nuremberg, six iterations so far, first one back in March 2014 And starting this year there are now two developer-centric events (both more or less claiming to be the first one):
developercamp¬†in W√ºrzburg, back in September 2016
swecamp¬†in Tennenlohe/Erlangen, right yesterday &amp;amp; today</description></item></channel></rss>