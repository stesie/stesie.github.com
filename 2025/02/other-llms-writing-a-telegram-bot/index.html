<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Other LLMs writing a Telegram Bot | ~stesie's musings</title>
<meta name=keywords content="AI,Claude,Telegram,Image Recognition"><meta name=description content="This is the fourth (and likely last) part in this mini series.
‚ÑπÔ∏è This post belongs to a mini series (I&rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:
In Claude writing a Telegram Bot, 1st try I&rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt In Other LLMs writing a Telegram Bot I quickly try DeepSeek and some more LLMs Since DeepSeek currently is all the rage, obviously I had to prompt it as well."><meta name=author content><link rel=canonical href=https://stefansiegl.de/2025/02/other-llms-writing-a-telegram-bot/><link crossorigin=anonymous href=/assets/css/stylesheet.cfda98f183e677d218f0f403640dca9927699a774ed1e85967ddc2265d9889f5.css integrity="sha256-z9qY8YPmd9IY8PQDZA3KmSdpmndO0ehZZ93CJl2YifU=" rel="preload stylesheet" as=style><link rel=icon href=https://stefansiegl.de/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://stefansiegl.de/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://stefansiegl.de/favicon-32x32.png><link rel=apple-touch-icon href=https://stefansiegl.de/apple-touch-icon.png><link rel=mask-icon href=https://stefansiegl.de/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://stefansiegl.de/2025/02/other-llms-writing-a-telegram-bot/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Other LLMs writing a Telegram Bot"><meta property="og:description" content="This is the fourth (and likely last) part in this mini series.
‚ÑπÔ∏è This post belongs to a mini series (I&rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:
In Claude writing a Telegram Bot, 1st try I&rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt In Other LLMs writing a Telegram Bot I quickly try DeepSeek and some more LLMs Since DeepSeek currently is all the rage, obviously I had to prompt it as well."><meta property="og:type" content="article"><meta property="og:url" content="https://stefansiegl.de/2025/02/other-llms-writing-a-telegram-bot/"><meta property="article:section" content="pages"><meta property="article:published_time" content="2025-02-02T00:00:00+00:00"><meta property="article:modified_time" content="2025-02-02T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Other LLMs writing a Telegram Bot"><meta name=twitter:description content="This is the fourth (and likely last) part in this mini series.
‚ÑπÔ∏è This post belongs to a mini series (I&rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:
In Claude writing a Telegram Bot, 1st try I&rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt In Other LLMs writing a Telegram Bot I quickly try DeepSeek and some more LLMs Since DeepSeek currently is all the rage, obviously I had to prompt it as well."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Pages","item":"https://stefansiegl.de/pages/"},{"@type":"ListItem","position":2,"name":"Other LLMs writing a Telegram Bot","item":"https://stefansiegl.de/2025/02/other-llms-writing-a-telegram-bot/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Other LLMs writing a Telegram Bot","name":"Other LLMs writing a Telegram Bot","description":"This is the fourth (and likely last) part in this mini series.\n‚ÑπÔ∏è This post belongs to a mini series (I\u0026rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:\nIn Claude writing a Telegram Bot, 1st try I\u0026rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt In Other LLMs writing a Telegram Bot I quickly try DeepSeek and some more LLMs Since DeepSeek currently is all the rage, obviously I had to prompt it as well.","keywords":["AI","Claude","Telegram","Image Recognition"],"articleBody":"This is the fourth (and likely last) part in this mini series.\n‚ÑπÔ∏è This post belongs to a mini series (I‚Äôm aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:\nIn Claude writing a Telegram Bot, 1st try I‚Äôm using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt In Other LLMs writing a Telegram Bot I quickly try DeepSeek and some more LLMs Since DeepSeek currently is all the rage, obviously I had to prompt it as well. So here we go\nDeepSeek V3 I go with the very same prompt that I used with my 3rd try on Claude Haiku:\nCreate a telegram chatbot in JavaScript. I want to take a photo of a gas meter. Upload to OpenAI API to read the gas meter. The number has five digits before comma, and three decimal places. Then store the value to a postgres database table and return it in the chat. For reference, here‚Äôs the full JavaScript code it spat out on first try\nWhat I found weird, that it initially has a code section where it hard-codes credentials and asks you to fill these like so:\n// Replace with your actual tokens and database credentials const TELEGRAM_BOT_TOKEN = 'YOUR_TELEGRAM_BOT_TOKEN'; const OPENAI_API_KEY = 'YOUR_OPENAI_API_KEY'; const DATABASE_URL = 'postgresql://user:password@localhost:5432/gas_meter_db'; ‚Ä¶ just to finally conclude with a note\nSecurity: Ensure your tokens and database credentials are stored securely, not hardcoded in the script.\nI mean, if you know it, why not use dotenv right away!? ü§∑\nAlso it hallucinated the OpenAI endpoint\n// Send the photo to OpenAI API for processing const response = await openai.createImageCompletion({ image: fileUrl, prompt: \"Extract the gas meter reading. The number has five digits before the comma and three decimal places.\" }); ‚Ä¶ that one just doesn‚Äôt exist. Image/text recognition works via the regular completion API (using one of the omni models).\nDeepSeek R1 Of course I had to run it against their new reasoning model ‚Äì especially since it also shares it‚Äôs reasoning monologue. So that is it‚Äôs reasoning:\nOkay, I need to create a Telegram chatbot using JavaScript that can take a photo of a gas meter, process it through the OpenAI API to read the numbers, store the value in a PostgreSQL database, and return it in the chat. Let me break this down step by step.\nFirst, the user mentioned using JavaScript, so I‚Äôll probably go with Node.js since it‚Äôs common for backend services. I‚Äôll need to set up a Telegram bot using the Telegram Bot API. The node-telegram-bot-api library is a popular choice for that.\nNext, handling photo uploads. When a user sends a photo, the bot needs to download it. Telegram provides a file ID, which I can use to get the file path and then download the image. I‚Äôll need to use the axios library or something similar to download the image from Telegram‚Äôs servers.\nThen, sending the image to the OpenAI API. Wait, does OpenAI have an API for OCR? I know they have GPT-4 with vision capabilities, so maybe using the Chat Completions API with the image as a part of the prompt. The user wants to extract a number with five digits before the comma and three decimal places. So the prompt should instruct the model to return the number in that format. I‚Äôll have to structure the API request correctly, including the image in base64 encoding.\nOnce the number is extracted, I need to validate it. The response from OpenAI might need some regex checking to ensure it‚Äôs in the correct format (#####,###). If it‚Äôs not valid, the bot should ask the user to try again.\nStoring the data in PostgreSQL. I‚Äôll need a PostgreSQL database set up. The pg library in Node.js can handle the connections. Create a table with columns for the user ID, the meter reading, and a timestamp. The bot should insert the validated number into this table.\nThen, the bot needs to send a confirmation message back to the user with the stored value. Maybe also include a history feature if the user wants to see previous entries, but the user didn‚Äôt mention that, so maybe stick to the basics.\nError handling is important. If the OpenAI API fails, or the image isn‚Äôt clear, the bot should notify the user. Also, handle cases where the response from OpenAI isn‚Äôt in the correct format.\nEnvironment variables for API keys and database credentials. Using dotenv to manage them. Security-wise, make sure not to expose these in the code.\nPutting it all together: the bot listens for photos, processes them through OpenAI, stores the result, and responds. Testing each part step by step would be crucial. Maybe start with the Telegram bot setup, then add image downloading, then integrate OpenAI, then database storage.\nPotential issues: image quality affecting OCR accuracy, rate limits on the OpenAI API, database connection problems. Need to handle exceptions and provide user feedback for each possible failure point.\nAlso, cost considerations. Using OpenAI‚Äôs API for image processing might incur costs, so the user should be aware of that. But that‚Äôs beyond the code itself.\nSo, the final code structure would involve initializing the bot, handling the ‚Äòphoto‚Äô message event, downloading the image, converting it to base64, sending to OpenAI with a prompt, parsing the response, validating the format, inserting into PostgreSQL, and replying to the user. Each step needs async/await handling since everything is asynchronous in Node.js.\nNeed to make sure the database table is correctly set up with the right schema. Maybe include a SQL script for creating the table.\nDocumentation in the code for clarity, and instructions on how to set up the environment variables and install dependencies.\nI really like (and at the same time I‚Äôm deeply impressed) how it touches on all the topics I‚Äôve addressed in the recent posts. It just ticks all the boxes, ‚Ä¶ compared to V3 it notes that it should use dotenv for improved security and also that it concludes to use the vision capabilities of the regular completion API.\nFor reference, here‚Äôs the full JavaScript code it spat out on first try.\nI also like the fact, that it went including emojis in the reply message, adding a nice touch like this:\n// Send confirmation bot.sendMessage(chatId, `‚úÖ Reading stored: ${reading}`); } catch (error) { console.error(error); bot.sendMessage(chatId, '‚ùå Error processing meter reading. Please try again.'); Llama 3.3 70B (and 3.1 405B) Failed to come up with a proper prompt to the third-party LLM:\n// Upload the photo to OpenAI API const openaiResponse = await axios.post('https://api.openai.com/v1/images/generate', { prompt: 'Read the gas meter value from the image', image: photoBuffer.toString('base64'), }, { headers: { 'Authorization': `Bearer ${openaiApiKey}`, 'Content-Type': 'application/json', }, }); First of all, why doesn‚Äôt it use a library, but call the API directly!?\nNext the URL is completely made up, there‚Äôs no such thing as /v1/images/generate. And why ‚Äúgenerate‚Äù at all? After all it‚Äôs about reading an image.\nLast but not least the prompt is a bit short. Why doesn‚Äôt it share the information on how many digits it is supposed to find?\nDirectly afterward it makes very strict assumptions on what it‚Äôs going to receive:\n// Extract the gas meter value from the OpenAI response const gasMeterValue = openaiResponse.data.choices[0].text; const regex = /^\\d{5},\\d{3}$/; if (regex.test(gasMeterValue)) { ‚Ä¶ which is likely to work in none of the cases. It even assumes a comma, instead of a point. Without asking the LLM for that, it‚Äôs (supposedly) never going to use that in it‚Äôs response.\nFor reference, here‚Äôs the full JavaScript source it spat out on first shot\nBy the way, very much the same happens with Llama 3.1 405B. That‚Äôs the LLM call it generates:\nconst response = await axios.post('https://api.openai.com/v1/images/generations', { prompt: 'Read the gas meter value from the image', n: 1, size: '256x256', response_format: 'json', image: image, }, { headers: { 'Authorization': `Bearer ${config.openai.apiKey}`, 'Content-Type': 'application/json', }, }); const gasMeterValue = response.data.data[0].text.trim(); const match = gasMeterValue.match(/^(\\d{5}),(\\d{3})$/); if (match) { return `${match[1]}.${match[2]}`; } else { throw new Error('Invalid gas meter value'); } ‚Ä¶ again, the call is completely made up and/or it didn‚Äôt ‚Äúunderstand‚Äù the job. After all it‚Äôs not supposed to generate an image, here it‚Äôs even asking for a 256x256 result ü§∑\nChatGPT Interestingly ChatGPT fails for the very same reason:\n// Upload image to OpenAI API for OCR processing const openAiResponse = await fetch('https://api.openai.com/v1/images/generate', { method: 'POST', headers: { 'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`, 'Content-Type': 'application/json', }, body: JSON.stringify({ image: buffer.toString('base64'), model: \"openai-ocr-model-id\", // Assuming OpenAI has a specific OCR model }), }); const data = await openAiResponse.json(); // Assuming the OCR API response contains a readable text of the gas reading const text = data.text.trim(); // Parse the reading (assuming format like \"12345.678\") const reading = parseFloat(text); ‚Ä¶ the API call is made up, I like the comment ‚ÄúAssuming OpenAI has a specific OCR model‚Äù. I mean, hey ChatGPT, you belong to OpenAI ‚Ä¶ you maybe should know best üòÇ\nI also quickly checked against o1-mini, which hardly did any better.\nConclusion I knew before that Claude 3.5, especially Sonnet, is really good at coding tasks. And the previous examples really underline that IMHO. Besides the new DeepSeek R1 it‚Äôs the only model that successfully addressed the task with a brief one-shot prompt.\nFurthermore I really like the reasoning output of DeepSeek R1, since it sheds some light into the problem domain, asks questions that one might want to address.\nComparing the prices, Claude 3.5 Sonnet API access currently is at input US$ 3,00 per MTOK (caches disabled) and output US$ 15,00 per MTOK.\nDeepSeek R1 is at input US$ 0,55 per MTOK and output US$ 2,19 per MTOK. Even including the tokens spent on the ‚Äúchain of thought‚Äù ‚Ä¶ it‚Äôs still way cheaper than Sonnet.\n","wordCount":"1658","inLanguage":"en","datePublished":"2025-02-02T00:00:00Z","dateModified":"2025-02-02T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://stefansiegl.de/2025/02/other-llms-writing-a-telegram-bot/"},"publisher":{"@type":"Organization","name":"~stesie's musings","logo":{"@type":"ImageObject","url":"https://stefansiegl.de/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://stefansiegl.de/ accesskey=h title="~stesie's musings (Alt + H)">~stesie's musings</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://stefansiegl.de/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://stefansiegl.de/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://stefansiegl.de/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://stefansiegl.de/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Other LLMs writing a Telegram Bot</h1><div class=post-meta>Status: üåø Budding&nbsp;¬∑&nbsp;Planted:&nbsp;<span title='2025-02-02 00:00:00 +0000 UTC'>Feb 2, 2025</span>&nbsp;¬∑&nbsp;8 min</div></header><div class=post-content><p>This is the fourth (and likely last) part in this mini series.</p><div class="admonition note"><div class=admonition-icon>‚ÑπÔ∏è</div><div class=admonition-body><p>This post belongs to a mini series (I&rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:</p><ul><li>In <a href=https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-1st-try/>Claude writing a Telegram Bot, 1st try</a> I&rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model</li><li>In <a href=https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-2nd-try/>Claude writing a Telegram Bot, 2nd try</a> I aim for a detailed one-shot prompt</li><li>In <a href=https://stefansiegl.de/2025/02/claude-writing-a-telegram-bot-3rd-try/>Claude writing a Telegram Bot, 3rd try</a> I try a rather short one-shot prompt</li><li>In <a href=https://stefansiegl.de/2025/02/other-llms-writing-a-telegram-bot/>Other LLMs writing a Telegram Bot</a> I quickly try DeepSeek and some more LLMs</li></ul></div></div><p>Since DeepSeek currently is all the rage, obviously I had to prompt it as well. So here we go</p><h2 id=deepseek-v3>DeepSeek V3<a hidden class=anchor aria-hidden=true href=#deepseek-v3>#</a></h2><p>I go with the very same prompt that I used with my 3rd try on Claude Haiku:</p><blockquote class=quote-request>Create a telegram chatbot in JavaScript. I want to take a photo of a gas meter. Upload to OpenAI API to read the gas meter. The number has five digits before comma, and three decimal places. Then store the value to a postgres database table and return it in the chat.</blockquote><p>For reference, <a href=https://gist.github.com/stesie/34c17f535de828d9e3b268093c6e3fc6>here&rsquo;s the full JavaScript code it spat out on first try</a></p><p>What I found weird, that it initially has a code section where it hard-codes credentials and asks you to fill these like so:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span><span style=color:#75715e>// Replace with your actual tokens and database credentials
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>TELEGRAM_BOT_TOKEN</span> <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;YOUR_TELEGRAM_BOT_TOKEN&#39;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>OPENAI_API_KEY</span> <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;YOUR_OPENAI_API_KEY&#39;</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>DATABASE_URL</span> <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;postgresql://user:password@localhost:5432/gas_meter_db&#39;</span>;
</span></span></code></pre></div><p>&mldr; just to finally conclude with a note</p><blockquote><p><strong>Security</strong>: Ensure your tokens and database credentials are stored securely, not hardcoded in the script.</p></blockquote><p>I mean, if you know it, why not use <code>dotenv</code> right away!? ü§∑</p><p>Also it hallucinated the OpenAI endpoint</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span> <span style=color:#75715e>// Send the photo to OpenAI API for processing
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>response</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>openai</span>.<span style=color:#a6e22e>createImageCompletion</span>({
</span></span><span style=display:flex><span>      <span style=color:#a6e22e>image</span><span style=color:#f92672>:</span> <span style=color:#a6e22e>fileUrl</span>,
</span></span><span style=display:flex><span>      <span style=color:#a6e22e>prompt</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;Extract the gas meter reading. The number has five digits before the comma and three decimal places.&#34;</span>
</span></span><span style=display:flex><span>    });
</span></span></code></pre></div><p>&mldr; that one just doesn&rsquo;t exist. Image/text recognition works via the regular completion API (using one of the omni models).</p><h2 id=deepseek-r1>DeepSeek R1<a hidden class=anchor aria-hidden=true href=#deepseek-r1>#</a></h2><p>Of course I had to run it against their new reasoning model &ndash; especially since it also shares it&rsquo;s reasoning monologue. So that is it&rsquo;s reasoning:</p><blockquote class=quote-response><p>Okay, I need to create a Telegram chatbot using JavaScript that can take a photo of a gas meter, process it through the OpenAI API to read the numbers, store the value in a PostgreSQL database, and return it in the chat. Let me break this down step by step.</p><p>First, the user mentioned using JavaScript, so I&rsquo;ll probably go with Node.js since it&rsquo;s common for backend services. I&rsquo;ll need to set up a Telegram bot using the Telegram Bot API. The <code>node-telegram-bot-api</code> library is a popular choice for that.</p><p>Next, handling photo uploads. When a user sends a photo, the bot needs to download it. Telegram provides a file ID, which I can use to get the file path and then download the image. I&rsquo;ll need to use the <code>axios</code> library or something similar to download the image from Telegram&rsquo;s servers.</p><p>Then, sending the image to the OpenAI API. Wait, does OpenAI have an API for OCR? I know they have GPT-4 with vision capabilities, so maybe using the Chat Completions API with the image as a part of the prompt. The user wants to extract a number with five digits before the comma and three decimal places. So the prompt should instruct the model to return the number in that format. I&rsquo;ll have to structure the API request correctly, including the image in base64 encoding.</p><p>Once the number is extracted, I need to validate it. The response from OpenAI might need some regex checking to ensure it&rsquo;s in the correct format (#####,###). If it&rsquo;s not valid, the bot should ask the user to try again.</p><p>Storing the data in PostgreSQL. I&rsquo;ll need a PostgreSQL database set up. The <code>pg</code> library in Node.js can handle the connections. Create a table with columns for the user ID, the meter reading, and a timestamp. The bot should insert the validated number into this table.</p><p>Then, the bot needs to send a confirmation message back to the user with the stored value. Maybe also include a history feature if the user wants to see previous entries, but the user didn&rsquo;t mention that, so maybe stick to the basics.</p><p>Error handling is important. If the OpenAI API fails, or the image isn&rsquo;t clear, the bot should notify the user. Also, handle cases where the response from OpenAI isn&rsquo;t in the correct format.</p><p>Environment variables for API keys and database credentials. Using <code>dotenv</code> to manage them. Security-wise, make sure not to expose these in the code.</p><p>Putting it all together: the bot listens for photos, processes them through OpenAI, stores the result, and responds. Testing each part step by step would be crucial. Maybe start with the Telegram bot setup, then add image downloading, then integrate OpenAI, then database storage.</p><p>Potential issues: image quality affecting OCR accuracy, rate limits on the OpenAI API, database connection problems. Need to handle exceptions and provide user feedback for each possible failure point.</p><p>Also, cost considerations. Using OpenAI&rsquo;s API for image processing might incur costs, so the user should be aware of that. But that&rsquo;s beyond the code itself.</p><p>So, the final code structure would involve initializing the bot, handling the &lsquo;photo&rsquo; message event, downloading the image, converting it to base64, sending to OpenAI with a prompt, parsing the response, validating the format, inserting into PostgreSQL, and replying to the user. Each step needs async/await handling since everything is asynchronous in Node.js.</p><p>Need to make sure the database table is correctly set up with the right schema. Maybe include a SQL script for creating the table.</p><p>Documentation in the code for clarity, and instructions on how to set up the environment variables and install dependencies.</p></blockquote><p>I really like (and at the same time I&rsquo;m deeply impressed) how it touches on all the topics I&rsquo;ve addressed in the recent posts. It just ticks all the boxes, &mldr; compared to V3 it notes that it should use <code>dotenv</code> for improved security and also that it concludes to use the vision capabilities of the regular completion API.</p><p>For reference, <a href=https://gist.github.com/stesie/96ea61d51ab49b709a35fb9d5e12e696>here&rsquo;s the full JavaScript code it spat out on first try</a>.</p><p>I also like the fact, that it went including emojis in the reply message, adding a nice touch like this:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span>    <span style=color:#75715e>// Send confirmation
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#a6e22e>bot</span>.<span style=color:#a6e22e>sendMessage</span>(<span style=color:#a6e22e>chatId</span>, <span style=color:#e6db74>`‚úÖ Reading stored: </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>reading</span><span style=color:#e6db74>}</span><span style=color:#e6db74>`</span>);
</span></span><span style=display:flex><span>  } <span style=color:#66d9ef>catch</span> (<span style=color:#a6e22e>error</span>) {
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>console</span>.<span style=color:#a6e22e>error</span>(<span style=color:#a6e22e>error</span>);
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>bot</span>.<span style=color:#a6e22e>sendMessage</span>(<span style=color:#a6e22e>chatId</span>, <span style=color:#e6db74>&#39;‚ùå Error processing meter reading. Please try again.&#39;</span>);
</span></span></code></pre></div><h2 id=llama-33-70b-and-31-405b>Llama 3.3 70B (and 3.1 405B)<a hidden class=anchor aria-hidden=true href=#llama-33-70b-and-31-405b>#</a></h2><p>Failed to come up with a proper prompt to the third-party LLM:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span><span style=color:#75715e>// Upload the photo to OpenAI API
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>openaiResponse</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>axios</span>.<span style=color:#a6e22e>post</span>(<span style=color:#e6db74>&#39;https://api.openai.com/v1/images/generate&#39;</span>, {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>prompt</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;Read the gas meter value from the image&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>image</span><span style=color:#f92672>:</span> <span style=color:#a6e22e>photoBuffer</span>.<span style=color:#a6e22e>toString</span>(<span style=color:#e6db74>&#39;base64&#39;</span>),
</span></span><span style=display:flex><span>}, {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>headers</span><span style=color:#f92672>:</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Authorization&#39;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>`Bearer </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>openaiApiKey</span><span style=color:#e6db74>}</span><span style=color:#e6db74>`</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Content-Type&#39;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;application/json&#39;</span>,
</span></span><span style=display:flex><span>  },
</span></span><span style=display:flex><span>});
</span></span></code></pre></div><ul><li><p>First of all, why doesn&rsquo;t it use a library, but call the API directly!?</p></li><li><p>Next the URL is completely made up, there&rsquo;s no such thing as <code>/v1/images/generate</code>. And why &ldquo;generate&rdquo; at all? After all it&rsquo;s about <em>reading</em> an image.</p></li><li><p>Last but not least the prompt is a bit short. Why doesn&rsquo;t it share the information on how many digits it is supposed to find?</p></li></ul><p>Directly afterward it makes very strict assumptions on what it&rsquo;s going to receive:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span><span style=color:#75715e>// Extract the gas meter value from the OpenAI response
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>gasMeterValue</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>openaiResponse</span>.<span style=color:#a6e22e>data</span>.<span style=color:#a6e22e>choices</span>[<span style=color:#ae81ff>0</span>].<span style=color:#a6e22e>text</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>regex</span> <span style=color:#f92672>=</span> <span style=color:#e6db74>/^\d{5},\d{3}$/</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> (<span style=color:#a6e22e>regex</span>.<span style=color:#a6e22e>test</span>(<span style=color:#a6e22e>gasMeterValue</span>)) {
</span></span></code></pre></div><p>&mldr; which is likely to work in none of the cases. It even assumes a comma, instead of a point. Without asking the LLM for that, it&rsquo;s (supposedly) never going to use that in it&rsquo;s response.</p><p>For reference, <a href=https://gist.github.com/stesie/37406b103050e068018765d485c25aef>here&rsquo;s the full JavaScript source it spat out on first shot</a></p><p>By the way, very much the same happens with Llama 3.1 405B. That&rsquo;s the LLM call it generates:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span> <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>response</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>axios</span>.<span style=color:#a6e22e>post</span>(<span style=color:#e6db74>&#39;https://api.openai.com/v1/images/generations&#39;</span>, {
</span></span><span style=display:flex><span>   <span style=color:#a6e22e>prompt</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;Read the gas meter value from the image&#39;</span>,
</span></span><span style=display:flex><span>   <span style=color:#a6e22e>n</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>   <span style=color:#a6e22e>size</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;256x256&#39;</span>,
</span></span><span style=display:flex><span>   <span style=color:#a6e22e>response_format</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;json&#39;</span>,
</span></span><span style=display:flex><span>   <span style=color:#a6e22e>image</span><span style=color:#f92672>:</span> <span style=color:#a6e22e>image</span>,
</span></span><span style=display:flex><span> }, {
</span></span><span style=display:flex><span>   <span style=color:#a6e22e>headers</span><span style=color:#f92672>:</span> {
</span></span><span style=display:flex><span>     <span style=color:#e6db74>&#39;Authorization&#39;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>`Bearer </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>config</span>.<span style=color:#a6e22e>openai</span>.<span style=color:#a6e22e>apiKey</span><span style=color:#e6db74>}</span><span style=color:#e6db74>`</span>,
</span></span><span style=display:flex><span>     <span style=color:#e6db74>&#39;Content-Type&#39;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;application/json&#39;</span>,
</span></span><span style=display:flex><span>   },
</span></span><span style=display:flex><span> });
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>gasMeterValue</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>response</span>.<span style=color:#a6e22e>data</span>.<span style=color:#a6e22e>data</span>[<span style=color:#ae81ff>0</span>].<span style=color:#a6e22e>text</span>.<span style=color:#a6e22e>trim</span>();
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>match</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>gasMeterValue</span>.<span style=color:#a6e22e>match</span>(<span style=color:#e6db74>/^(\d{5}),(\d{3})$/</span>);
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> (<span style=color:#a6e22e>match</span>) {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> <span style=color:#e6db74>`</span><span style=color:#e6db74>${</span><span style=color:#a6e22e>match</span>[<span style=color:#ae81ff>1</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>.</span><span style=color:#e6db74>${</span><span style=color:#a6e22e>match</span>[<span style=color:#ae81ff>2</span>]<span style=color:#e6db74>}</span><span style=color:#e6db74>`</span>;
</span></span><span style=display:flex><span>} <span style=color:#66d9ef>else</span> {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>throw</span> <span style=color:#66d9ef>new</span> Error(<span style=color:#e6db74>&#39;Invalid gas meter value&#39;</span>);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>&mldr; again, the call is completely made up and/or it didn&rsquo;t &ldquo;understand&rdquo; the job. After all it&rsquo;s not supposed to generate an image, here it&rsquo;s even asking for a 256x256 result ü§∑</p><h2 id=chatgpt>ChatGPT<a hidden class=anchor aria-hidden=true href=#chatgpt>#</a></h2><p>Interestingly ChatGPT fails for the very same reason:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span><span style=color:#75715e>// Upload image to OpenAI API for OCR processing
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>openAiResponse</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>fetch</span>(<span style=color:#e6db74>&#39;https://api.openai.com/v1/images/generate&#39;</span>, {
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>method</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;POST&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>headers</span><span style=color:#f92672>:</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Authorization&#39;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>`Bearer </span><span style=color:#e6db74>${</span><span style=color:#a6e22e>process</span>.<span style=color:#a6e22e>env</span>.<span style=color:#a6e22e>OPENAI_API_KEY</span><span style=color:#e6db74>}</span><span style=color:#e6db74>`</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;Content-Type&#39;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;application/json&#39;</span>,
</span></span><span style=display:flex><span>  },
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>body</span><span style=color:#f92672>:</span> <span style=color:#a6e22e>JSON</span>.<span style=color:#a6e22e>stringify</span>({
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>image</span><span style=color:#f92672>:</span> <span style=color:#a6e22e>buffer</span>.<span style=color:#a6e22e>toString</span>(<span style=color:#e6db74>&#39;base64&#39;</span>),
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>model</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;openai-ocr-model-id&#34;</span>, <span style=color:#75715e>// Assuming OpenAI has a specific OCR model
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  }),
</span></span><span style=display:flex><span>});
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>data</span> <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> <span style=color:#a6e22e>openAiResponse</span>.<span style=color:#a6e22e>json</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Assuming the OCR API response contains a readable text of the gas reading
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>text</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>data</span>.<span style=color:#a6e22e>text</span>.<span style=color:#a6e22e>trim</span>();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Parse the reading (assuming format like &#34;12345.678&#34;)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>reading</span> <span style=color:#f92672>=</span> parseFloat(<span style=color:#a6e22e>text</span>);
</span></span></code></pre></div><p>&mldr; the API call is made up, I like the comment &ldquo;Assuming OpenAI has a specific OCR model&rdquo;. I mean, hey ChatGPT, you belong to OpenAI &mldr; you maybe should know best üòÇ</p><p>I also quickly checked against o1-mini, which hardly did any better.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>I knew before that Claude 3.5, especially Sonnet, is really good at coding tasks. And the previous examples really underline that IMHO. Besides the new DeepSeek R1 it&rsquo;s the only model that successfully addressed the task with a brief one-shot prompt.</p><p>Furthermore I really like the reasoning output of DeepSeek R1, since it sheds some light into the problem domain, asks questions that one might want to address.</p><p>Comparing the prices, Claude 3.5 Sonnet API access currently is at input US$ 3,00 per MTOK (caches disabled) and output US$ 15,00 per MTOK.</p><p>DeepSeek R1 is at input US$ 0,55 per MTOK and output US$ 2,19 per MTOK. Even including the tokens spent on the &ldquo;chain of thought&rdquo; &mldr; it&rsquo;s still way cheaper than Sonnet.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://stefansiegl.de/tags/ai/>AI</a></li><li><a href=https://stefansiegl.de/tags/claude/>Claude</a></li><li><a href=https://stefansiegl.de/tags/telegram/>Telegram</a></li><li><a href=https://stefansiegl.de/tags/image-recognition/>Image Recognition</a></li></ul></footer></article></main><footer class=footer><span>¬© 2025 Stefan Siegl ¬∑ all content is <a href=https://creativecommons.org/licenses/by-sa/4.0/deed>CC-BY-SA</a> ¬∑ <a href=https://www.swyx.io/digital-garden-tos#for-visitors>Terms of Service</a></span> ¬∑
<a href=/imprint>Imprint</a> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>