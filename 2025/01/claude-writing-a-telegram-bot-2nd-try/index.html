<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Claude writing a Telegram Bot, 2nd try | ~stesie's musings</title>
<meta name=keywords content="AI,Claude,Telegram,Image Recognition"><meta name=description content="This is the second part of the mini series on writing Telegram bots to read my gas meter using Claude.
‚ÑπÔ∏è This post belongs to a mini series (I&rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:
In Claude writing a Telegram Bot, 1st try I&rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt Like in the first round, I will first show the full dialog I&rsquo;ve used to let it generate the implementation."><meta name=author content><link rel=canonical href=https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-2nd-try/><link crossorigin=anonymous href=/assets/css/stylesheet.0669d81ae9c5ebf0731aafcbac037c15b990f9546c445660f4b04f769073cc7a.css integrity="sha256-BmnYGunF6/BzGq/LrAN8FbmQ+VRsRFZg9LBPdpBzzHo=" rel="preload stylesheet" as=style><link rel=icon href=https://stefansiegl.de/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://stefansiegl.de/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://stefansiegl.de/favicon-32x32.png><link rel=apple-touch-icon href=https://stefansiegl.de/apple-touch-icon.png><link rel=mask-icon href=https://stefansiegl.de/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-2nd-try/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Claude writing a Telegram Bot, 2nd try"><meta property="og:description" content="This is the second part of the mini series on writing Telegram bots to read my gas meter using Claude.
‚ÑπÔ∏è This post belongs to a mini series (I&rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:
In Claude writing a Telegram Bot, 1st try I&rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt Like in the first round, I will first show the full dialog I&rsquo;ve used to let it generate the implementation."><meta property="og:type" content="article"><meta property="og:url" content="https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-2nd-try/"><meta property="article:section" content="pages"><meta property="article:published_time" content="2025-01-28T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-30T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Claude writing a Telegram Bot, 2nd try"><meta name=twitter:description content="This is the second part of the mini series on writing Telegram bots to read my gas meter using Claude.
‚ÑπÔ∏è This post belongs to a mini series (I&rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:
In Claude writing a Telegram Bot, 1st try I&rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt Like in the first round, I will first show the full dialog I&rsquo;ve used to let it generate the implementation."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Pages","item":"https://stefansiegl.de/pages/"},{"@type":"ListItem","position":2,"name":"Claude writing a Telegram Bot, 2nd try","item":"https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-2nd-try/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Claude writing a Telegram Bot, 2nd try","name":"Claude writing a Telegram Bot, 2nd try","description":"This is the second part of the mini series on writing Telegram bots to read my gas meter using Claude.\n‚ÑπÔ∏è This post belongs to a mini series (I\u0026rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:\nIn Claude writing a Telegram Bot, 1st try I\u0026rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt Like in the first round, I will first show the full dialog I\u0026rsquo;ve used to let it generate the implementation.","keywords":["AI","Claude","Telegram","Image Recognition"],"articleBody":"This is the second part of the mini series on writing Telegram bots to read my gas meter using Claude.\n‚ÑπÔ∏è This post belongs to a mini series (I‚Äôm aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:\nIn Claude writing a Telegram Bot, 1st try I‚Äôm using an elaborate, step-by-step prompting strategy with Haiku model In Claude writing a Telegram Bot, 2nd try I aim for a detailed one-shot prompt In Claude writing a Telegram Bot, 3rd try I try a rather short one-shot prompt Like in the first round, I will first show the full dialog I‚Äôve used to let it generate the implementation. Then following up with a discussion of the code and some final thoughts.\nThis time, I aim to provide a more concise approach by offering a single prompt that encompasses all the necessary steps to achieve our goal.\nCreate a Telegram chatbot in JavaScript. The bot receives an image that is sent to it, shall then scale it to have 1000 pixels or less on the longer edge. Then upload the image to OpenAPI gpt-4o model along with the prompt ‚ÄúWie lautet der Z√§hlerstand auf dem Foto des Gasz√§hlers. Die Zahl hat f√ºnf Ziffern vor dem Komma und drei Nachkommastellen. Gib nur die Zahl aus, keinen Text davor oder danach‚Äù. Take the resulting number, store it to a database table named gas_meter, along with the current timestamp. Furthermore return the extracted number within the telegram communication, so the chat contact has some feedback. I‚Äôll help you create a Telegram chatbot in JavaScript for processing gas meter images. I‚Äôll break this down into key components.\nThis implementation requires:\nTelegram bot token OpenAI API key PostgreSQL database connection npm packages: telegraf, axios, sharp, pg, openai Database setup:\nCREATE TABLE gas_meter ( id SERIAL PRIMARY KEY, reading NUMERIC(8,3), timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP ); Recommended environment variables:\nTELEGRAM_BOT_TOKEN OPENAI_API_KEY DATABASE_URL Would you like me to elaborate on any specific part of the implementation?\nLooking at the code, I immediately noticed, that I forgot to mention that I want support for .env files and also that it must expect the LLM to reply with German number formatting (using a comma to separate the decimal places), ‚Ä¶ quite like I had with the first try. So let‚Äôs fix this:\nconsider that the reading, as returned by the LLM, might use a comma as decimal separator (due to the German prompt). Also read environment variables from an .env file, if it exists Key changes:\nAdded dotenv to load .env file Modified extractMeterReading() to replace comma with dot Converted reading to parseFloat() for correct number parsing Requires npm install dotenv in addition to previous dependencies.\nRunning it for the first time I noticed it‚Äôs calling the LLM wrongly\nthe code causes the following openai error:\nError processing image: BadRequestError: 400 Invalid value: ‚Äòimage‚Äô. Supported values are: ‚Äôtext‚Äô, ‚Äòimage_url‚Äô, ‚Äòinput_audio‚Äô, ‚Äòrefusal‚Äô, ‚Äòaudio‚Äô, and ‚Äòfile‚Äô.\nfigure out what‚Äôs wrong please\nKey changes:\nUse image_url instead of image Write image to temporary file Convert image to base64 using file-based method Ensure cleanup of temporary file This approach resolves the OpenAI API image submission issue by using the correct image_url format.\nI‚Äôve uploaded the generated JavaScript code to GitHub.\nCode Review Compared to the results of the first iteration I like that this time it‚Äôs using axios for all http requests. Be it downloading from Telegram image storage, be it the call to the LLM.\nWhen scaling the image, I think it‚Äôs interesting how it calculates the target image size (considering the aspect ratio) manually this time, where it simply delegated that stuff to sharp with the first implementation.\nWhat I really find weird is the way how it‚Äôs converting the ArrayBuffer from sharp to a base64-encoded Buffer, which it‚Äôs passing on to the LLM. To do so it first writes the ArrayBuffer to disk, just to re-read it immediately after, like this:\nconst tempFilePath = `/tmp/gas_meter_${Date.now()}.jpg`; // Write buffer to temporary file fs.writeFileSync(tempFilePath, imageBuffer); // Read file and convert to base64 const fileBuffer = fs.readFileSync(tempFilePath); const base64Image = fileBuffer.toString('base64'); ‚Ä¶ would this be an actual code review situation, I very likely would address this. Especially since the guessable filename might pose a security risk.\nInstead this should just do the trick in one go:\nconst base64Image = Buffer.from(imageBuffer).toString('base64'); Furthermore, the way it‚Äôs (not) handling errors from the LLM invokation, it would not remove the temporary file, if the LLM invocation fails.\nAs mentioned earlier, the above code was produced by Claude 3.5 Haiku. I‚Äôve later on tried the same prompt with Sonnet, and that just directly converted the ArrayBuffer as shown by me.\nFinal thoughts All in all another nice solution to the problem, that just works fine :-)\nThis demonstrates that it‚Äôs not always essential to be overly wordy when giving guidance, unlike I initially did. However, breaking it down into individual steps, also aids personal understanding. Moreover, since I haven‚Äôt created a Telegram bot before and it‚Äôs been a while since I‚Äôve scaled an image using Node.js, examining code samples in detail has helped me gain insights.\nObserving the variations in how the sharp library is used with the .resize(...) function, it brings to mind the differing approaches that two human developers might take when writing code. Similar to Claude‚Äôs example, it is possible for two individuals to reach different conclusions, with one opting to manually calculate the aspect ratio and the other choosing to utilize the library‚Äôs built-in features.\n‚ÑπÔ∏è There‚Äôs a follow-up to this article, where I tried a very short one-shot prompt and compare the results: Claude writing a Telegram Bot, 3rd try. ","wordCount":"945","inLanguage":"en","datePublished":"2025-01-28T00:00:00Z","dateModified":"2025-01-30T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-2nd-try/"},"publisher":{"@type":"Organization","name":"~stesie's musings","logo":{"@type":"ImageObject","url":"https://stefansiegl.de/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://stefansiegl.de/ accesskey=h title="~stesie's musings (Alt + H)">~stesie's musings</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://stefansiegl.de/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://stefansiegl.de/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://stefansiegl.de/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://stefansiegl.de/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Claude writing a Telegram Bot, 2nd try</h1><div class=post-meta>Status: üå± Seedling&nbsp;¬∑&nbsp;Planted:&nbsp;<span title='2025-01-28 00:00:00 +0000 UTC'>Jan 28, 2025</span>&nbsp;¬∑&nbsp;Last tended:&nbsp;<span title='2025-01-30 00:00:00 +0000 UTC'>Jan 30, 2025</span>&nbsp;¬∑&nbsp;5 min</div></header><div class=post-content><p>This is the second part of the mini series on writing Telegram bots to read my gas meter using Claude.</p><div class="admonition note"><div class=admonition-icon>‚ÑπÔ∏è</div><div class=admonition-body><p>This post belongs to a mini series (I&rsquo;m aiming for three posts in a row), where I try prompting Claude with different levels of verbosity and compare the results:</p><ul><li>In <a href=https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-1st-try/>Claude writing a Telegram Bot, 1st try</a> I&rsquo;m using an elaborate, step-by-step prompting strategy with Haiku model</li><li>In <a href=https://stefansiegl.de/2025/01/claude-writing-a-telegram-bot-2nd-try/>Claude writing a Telegram Bot, 2nd try</a> I aim for a detailed one-shot prompt</li><li>In <a href=https://stefansiegl.de/2025/02/claude-writing-a-telegram-bot-3rd-try/>Claude writing a Telegram Bot, 3rd try</a> I try a rather short one-shot prompt</li></ul></div></div><p>Like in the first round, I will first show the full dialog I&rsquo;ve used to let it generate the implementation. Then following up with a discussion of the code and some final thoughts.</p><p>This time, I aim to provide a more concise approach by offering a single prompt that encompasses all the necessary steps to achieve our goal.</p><blockquote class=quote-request>Create a Telegram chatbot in JavaScript. The bot receives an image that is sent to it, shall then scale it to have 1000 pixels or less on the longer edge. Then upload the image to OpenAPI gpt-4o model along with the prompt &ldquo;Wie lautet der Z√§hlerstand auf dem Foto des Gasz√§hlers. Die Zahl hat f√ºnf Ziffern vor dem Komma und drei Nachkommastellen. Gib nur die Zahl aus, keinen Text davor oder danach&rdquo;. Take the resulting number, store it to a database table named gas_meter, along with the current timestamp. Furthermore return the extracted number within the telegram communication, so the chat contact has some feedback.</blockquote><blockquote class=quote-response><p>I&rsquo;ll help you create a Telegram chatbot in JavaScript for processing gas meter images. I&rsquo;ll break this down into key components.</p><p>This implementation requires:</p><ul><li>Telegram bot token</li><li>OpenAI API key</li><li>PostgreSQL database connection</li><li>npm packages: telegraf, axios, sharp, pg, openai</li></ul><p>Database setup:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#66d9ef>CREATE</span> <span style=color:#66d9ef>TABLE</span> gas_meter (
</span></span><span style=display:flex><span>  id SERIAL <span style=color:#66d9ef>PRIMARY</span> <span style=color:#66d9ef>KEY</span>,
</span></span><span style=display:flex><span>  reading NUMERIC(<span style=color:#ae81ff>8</span>,<span style=color:#ae81ff>3</span>),
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>timestamp</span> <span style=color:#66d9ef>TIMESTAMP</span> <span style=color:#66d9ef>DEFAULT</span> <span style=color:#66d9ef>CURRENT_TIMESTAMP</span>
</span></span><span style=display:flex><span>);
</span></span></code></pre></div><p>Recommended environment variables:</p><ul><li>TELEGRAM_BOT_TOKEN</li><li>OPENAI_API_KEY</li><li>DATABASE_URL</li></ul><p>Would you like me to elaborate on any specific part of the implementation?</p></blockquote><p>Looking at the code, I immediately noticed, that I forgot to mention that I want support for <code>.env</code> files and also that it must expect the LLM to reply with German number formatting (using a comma to separate the decimal places), &mldr; quite like I had with the first try.
So let&rsquo;s fix this:</p><blockquote class=quote-request>consider that the reading, as returned by the LLM, might use a comma as decimal separator (due to the German prompt). Also read environment variables from an .env file, if it exists</blockquote><blockquote class=quote-response><p>Key changes:</p><ul><li>Added <code>dotenv</code> to load <code>.env</code> file</li><li>Modified <code>extractMeterReading()</code> to replace comma with dot</li><li>Converted reading to <code>parseFloat()</code> for correct number parsing</li></ul><p>Requires npm install dotenv in addition to previous dependencies.</p></blockquote><p>Running it for the first time I noticed it&rsquo;s calling the LLM wrongly</p><blockquote class=quote-request><p>the code causes the following openai error:</p><p>Error processing image: BadRequestError: 400 Invalid value: &lsquo;image&rsquo;. Supported values are: &rsquo;text&rsquo;, &lsquo;image_url&rsquo;, &lsquo;input_audio&rsquo;, &lsquo;refusal&rsquo;, &lsquo;audio&rsquo;, and &lsquo;file&rsquo;.</p><p>figure out what&rsquo;s wrong please</p></blockquote><blockquote class=quote-response><p>Key changes:</p><ul><li>Use <code>image_url</code> instead of image</li><li>Write image to temporary file</li><li>Convert image to base64 using file-based method</li><li>Ensure cleanup of temporary file</li></ul><p>This approach resolves the OpenAI API image submission issue by using the correct <code>image_url</code> format.</p></blockquote><p>I&rsquo;ve uploaded the <a href=https://github.com/stesie/gaszaehler-bot-2/blob/main/telegram-gas-meter-bot.js>generated JavaScript code to GitHub</a>.</p><h2 id=code-review>Code Review<a hidden class=anchor aria-hidden=true href=#code-review>#</a></h2><p>Compared to the results of the first iteration I like that this time it&rsquo;s using <code>axios</code> for all http requests. Be it downloading from Telegram image storage, be it the call to the LLM.</p><p>When scaling the image, I think it&rsquo;s interesting how it calculates the target image size (considering the aspect ratio) manually this time, where it simply delegated that stuff to <code>sharp</code> with the first implementation.</p><p>What I really find weird is the way how it&rsquo;s converting the <code>ArrayBuffer</code> from <code>sharp</code> to a base64-encoded <code>Buffer</code>, which it&rsquo;s passing on to the LLM. To do so it first writes the <code>ArrayBuffer</code> to disk, just to re-read it immediately after, like this:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>tempFilePath</span> <span style=color:#f92672>=</span> <span style=color:#e6db74>`/tmp/gas_meter_</span><span style=color:#e6db74>${</span>Date.<span style=color:#a6e22e>now</span>()<span style=color:#e6db74>}</span><span style=color:#e6db74>.jpg`</span>;
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>  <span style=color:#75715e>// Write buffer to temporary file
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#a6e22e>fs</span>.<span style=color:#a6e22e>writeFileSync</span>(<span style=color:#a6e22e>tempFilePath</span>, <span style=color:#a6e22e>imageBuffer</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e>// Read file and convert to base64
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>fileBuffer</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>fs</span>.<span style=color:#a6e22e>readFileSync</span>(<span style=color:#a6e22e>tempFilePath</span>);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>const</span> <span style=color:#a6e22e>base64Image</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>fileBuffer</span>.<span style=color:#a6e22e>toString</span>(<span style=color:#e6db74>&#39;base64&#39;</span>);
</span></span></code></pre></div><p>&mldr; would this be an actual code review situation, I very likely would address this.
Especially since the guessable filename might pose a security risk.</p><p>Instead this should just do the trick in one go:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-js data-lang=js><span style=display:flex><span><span style=color:#66d9ef>const</span> <span style=color:#a6e22e>base64Image</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>Buffer</span>.<span style=color:#a6e22e>from</span>(<span style=color:#a6e22e>imageBuffer</span>).<span style=color:#a6e22e>toString</span>(<span style=color:#e6db74>&#39;base64&#39;</span>);
</span></span></code></pre></div><p>Furthermore, the way it&rsquo;s (not) handling errors from the LLM invokation, it would not remove the temporary file, if the LLM invocation fails.</p><p>As mentioned earlier, the above code was produced by Claude 3.5 <strong>Haiku</strong>. I&rsquo;ve later on tried the same prompt with Sonnet, and that just directly converted the <code>ArrayBuffer</code> as shown by me.</p><h2 id=final-thoughts>Final thoughts<a hidden class=anchor aria-hidden=true href=#final-thoughts>#</a></h2><p>All in all another nice solution to the problem, that just works fine :-)</p><p>This demonstrates that it&rsquo;s not always essential to be overly wordy when giving guidance, unlike I initially did. However, breaking it down into individual steps, also aids personal understanding. Moreover, since I haven&rsquo;t created a Telegram bot before and it&rsquo;s been a while since I&rsquo;ve scaled an image using Node.js, examining code samples in detail has helped me gain insights.</p><p>Observing the variations in how the <code>sharp</code> library is used with the <code>.resize(...)</code> function, it brings to mind the differing approaches that two human developers might take when writing code. Similar to Claude&rsquo;s example, it is possible for two individuals to reach different conclusions, with one opting to manually calculate the aspect ratio and the other choosing to utilize the library&rsquo;s built-in features.</p><div class="admonition note"><div class=admonition-icon>‚ÑπÔ∏è</div><div class=admonition-body>There&rsquo;s a follow-up to this article, where I tried a very short one-shot prompt and compare the results: <a href=https://stefansiegl.de/2025/02/claude-writing-a-telegram-bot-3rd-try/>Claude writing a Telegram Bot, 3rd try</a>.</div></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://stefansiegl.de/tags/ai/>AI</a></li><li><a href=https://stefansiegl.de/tags/claude/>Claude</a></li><li><a href=https://stefansiegl.de/tags/telegram/>Telegram</a></li><li><a href=https://stefansiegl.de/tags/image-recognition/>Image Recognition</a></li></ul></footer></article></main><footer class=footer><span>¬© 2025 Stefan Siegl ¬∑ all content is <a href=https://creativecommons.org/licenses/by-sa/4.0/deed>CC-BY-SA</a> ¬∑ <a href=https://www.swyx.io/digital-garden-tos#for-visitors>Terms of Service</a></span> ¬∑
<a href=/imprint>Imprint</a> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>