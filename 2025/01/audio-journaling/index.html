<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Audio Journaling | ~stesie's musings</title>
<meta name=keywords content="Audio Journaling,Whisper,Logseq"><meta name=description content="For quite some time now, I&rsquo;ve been using Logseq as my personal knowledge management system. It has been an invaluable tool for organizing my thoughts, projects, and ideas. A few months ago, I decided to take it a step further by incorporating journaling into my daily routine. Each morning and evening, I reflect on how I&rsquo;m feeling, what has moved me, what went well during the day, where I excelled, and where there might be room for improvement."><meta name=author content><link rel=canonical href=https://stefansiegl.de/2025/01/audio-journaling/><link crossorigin=anonymous href=/assets/css/stylesheet.0c89971808195fcfba02b00128bb5209e165ff89d76c2f0d04eaefef9e1bd82a.css integrity="sha256-DImXGAgZX8+6ArABKLtSCeFl/4nXbC8NBOrv754b2Co=" rel="preload stylesheet" as=style><link rel=icon href=https://stefansiegl.de/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://stefansiegl.de/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://stefansiegl.de/favicon-32x32.png><link rel=apple-touch-icon href=https://stefansiegl.de/apple-touch-icon.png><link rel=mask-icon href=https://stefansiegl.de/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://stefansiegl.de/2025/01/audio-journaling/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=me href=https://wue.social/@rolf><meta property="og:title" content="Audio Journaling"><meta property="og:description" content="For quite some time now, I&rsquo;ve been using Logseq as my personal knowledge management system. It has been an invaluable tool for organizing my thoughts, projects, and ideas. A few months ago, I decided to take it a step further by incorporating journaling into my daily routine. Each morning and evening, I reflect on how I&rsquo;m feeling, what has moved me, what went well during the day, where I excelled, and where there might be room for improvement."><meta property="og:type" content="article"><meta property="og:url" content="https://stefansiegl.de/2025/01/audio-journaling/"><meta property="article:section" content="pages"><meta property="article:published_time" content="2025-01-30T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-30T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Audio Journaling"><meta name=twitter:description content="For quite some time now, I&rsquo;ve been using Logseq as my personal knowledge management system. It has been an invaluable tool for organizing my thoughts, projects, and ideas. A few months ago, I decided to take it a step further by incorporating journaling into my daily routine. Each morning and evening, I reflect on how I&rsquo;m feeling, what has moved me, what went well during the day, where I excelled, and where there might be room for improvement."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Pages","item":"https://stefansiegl.de/pages/"},{"@type":"ListItem","position":2,"name":"Audio Journaling","item":"https://stefansiegl.de/2025/01/audio-journaling/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Audio Journaling","name":"Audio Journaling","description":"For quite some time now, I\u0026rsquo;ve been using Logseq as my personal knowledge management system. It has been an invaluable tool for organizing my thoughts, projects, and ideas. A few months ago, I decided to take it a step further by incorporating journaling into my daily routine. Each morning and evening, I reflect on how I\u0026rsquo;m feeling, what has moved me, what went well during the day, where I excelled, and where there might be room for improvement.","keywords":["Audio Journaling","Whisper","Logseq"],"articleBody":"For quite some time now, Ive been using Logseq as my personal knowledge management system. It has been an invaluable tool for organizing my thoughts, projects, and ideas. A few months ago, I decided to take it a step further by incorporating journaling into my daily routine. Each morning and evening, I reflect on how Im feeling, what has moved me, what went well during the day, where I excelled, and where there might be room for improvement.\nThis daily journaling practice has led me to spend even more time at the computer, diving into topics that interest me. Yet, I often find myself falling down rabbit holes, getting sidetracked from my main goal of reflection and wrapping up the day.\nA few weeks ago, I stumbled upon a journal entry by Brian Sunter, where he shared his thoughts on audio journaling. He uses the Voice Memos app on his iPhone to record his thoughts, then shares the file with Logseq. From there, he employs Whisper and his GPT plugin to derive the content he needs. While his idea didnt immediately resonate with meI couldnt see myself journaling during a walk, nor did I want to keep audio files in my Logseq assetsit did spark an interest in exploring audio journaling further.\nThomas Frank also wrote an article on the subject and created several YouTube videos. He uses Pipedreams to push data into Notion, which is an interesting approach but more suited to Notions web-based API system.\nMy Current Solution To ease into audio journaling while keeping it simple, Ive devised the following workflow:\nRecord a voice memo on my iPhone. Share the recording via the Nextcloud app. (The next morning) Process the audio file with OpenAI Whisper. Run the transcript through a language model to correct names, remove filler words, and summarize the text into bullet points. Copy and paste the results into Logseq. Ive consolidated the last three steps into a small shell script that processes the latest file, transcribes it, and runs it through a language model. The output is automatically copied to the clipboard, allowing me to simply press Control+V in Logseq.\nAutomating Transcription OpenAI Whisper is open source and easy to install. On Arch Linux, you can set it up with sudo pacman -S python-openai-whisper. Running whisper \"New Recording.m4a\" --language German provides initial results. However, on my Thinkpad without a powerful graphics card, it takes quite a while.\nFor the impatient (like me), theres a paid API option:\ncurl --request POST \\ --url https://api.openai.com/v1/audio/transcriptions \\ --header \"Authorization: Bearer $OPENAI_API_KEY\" \\ --header 'Content-Type: multipart/form-data' \\ --form file=@'New Recording.m4a' \\ --form model=whisper-1 -F response_format=text -o out In just a second or two, you get a transcript of your lengthy recording.\nSummarizing with the Language Model Now that we have a transcript, its still more of a ramble than concise answers to my daily reflection questions. Software project names and peoples names might also be misspelled.\nIve come to appreciate the Python module llm as a CLI tool for interacting with language models. On Arch, its conveniently installed with python-pipx. Simply run pipx install llm. Done.\nThe advantage of this tool is its ability to pipe files through standard input and abstract different language models. Whether using a local Llama model or one hosted on AWS Bedrock, Claude, or OpenAI, the command remains the same. You can also set a template with maximum token count, temperature, and system prompt.\nHeres the command to use:\nllm --system \"$(cat system.txt)\" -o max_tokens 4096 --save audio-journal To trigger it, simply run:\nllm -t audio-journal \u003c out 癸 System Prompt\nThe system prompt is highly personal, but Im happy to share mine for inspiration (actually mine is in German language):\nYou are a helpful assistant preparing transcribed audio notes for a journal. The focus is on evening reflection questions. The journal is in German. Summarize the answers concisely using bullet points, but form complete sentences. Remove filler words and phrases. Each bullet point should start with [[gpt]]. If a bullet point is too long, split it into two or more points.\nCorrect misspelled project and product names.\nCorrect misspelled names of people. Add last names if I only mention the first name and its clear. Names should also be enclosed in square brackets, e.g., [[Max Mustermann]].\nNames of friends: XXX\nNames of some colleagues: XXX\nNicknames: XXX is YYY, XXX is YYY. Replace nicknames with full names.\nNames of software projects, etc., that might be mentioned: Logseq, Todoist, Claude, Chat-GPT, Deepseek, Llama, cadiff\nYour response should be formatted as follows:\n[[Evening Questions]] #daily [[How Am I feeling?]] [[gpt]] Insert bullet points from transcript here [[gpt]] Repeat line if necessary [[Whats Something Good That Happened Today?]] [[gpt]] Insert bullet points from transcript here [[gpt]] Repeat line if necessary [[What Did I Do Well?]] [[gpt]] Insert bullet points from transcript here [[gpt]] Repeat line if necessary [[What Could I Have Done Better?]] [[gpt]] Insert bullet points from transcript here [[gpt]] Repeat line if necessary [[What Am I Thinking of?]] [[gpt]] Insert bullet points from transcript here [[gpt]] Repeat line if necessary ","wordCount":"847","inLanguage":"en","datePublished":"2025-01-30T00:00:00Z","dateModified":"2025-01-30T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://stefansiegl.de/2025/01/audio-journaling/"},"publisher":{"@type":"Organization","name":"~stesie's musings","logo":{"@type":"ImageObject","url":"https://stefansiegl.de/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://stefansiegl.de/ accesskey=h title="~stesie's musings (Alt + H)">~stesie's musings</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://stefansiegl.de/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://stefansiegl.de/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://stefansiegl.de/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://stefansiegl.de/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Audio Journaling</h1><div class=post-meta>Status:  Seedling&nbsp;路&nbsp;Planted:&nbsp;<span title='2025-01-30 00:00:00 +0000 UTC'>Jan 30, 2025</span>&nbsp;路&nbsp;4 min</div></header><div class=post-content><p>For quite some time now, I&rsquo;ve been using Logseq as my personal knowledge management system. It has been an invaluable tool for organizing my thoughts, projects, and ideas. A few months ago, I decided to take it a step further by incorporating journaling into my daily routine. Each morning and evening, I reflect on how I&rsquo;m feeling, what has moved me, what went well during the day, where I excelled, and where there might be room for improvement.</p><p>This daily journaling practice has led me to spend even more time at the computer, diving into topics that interest me. Yet, I often find myself falling down rabbit holes, getting sidetracked from my main goal of reflection and wrapping up the day.</p><p>A few weeks ago, I stumbled upon a <a href=https://github.com/briansunter/graph/blob/master/logseq/journals/2023_06_10.md>journal entry by Brian Sunter</a>, where he shared his thoughts on audio journaling. He uses the Voice Memos app on his iPhone to record his thoughts, then shares the file with Logseq. From there, he employs Whisper and his GPT plugin to derive the content he needs. While his idea didn&rsquo;t immediately resonate with meI couldn&rsquo;t see myself journaling during a walk, nor did I want to keep audio files in my Logseq assetsit did spark an interest in exploring audio journaling further.</p><p><a href=https://thomasjfrank.com/how-to-transcribe-audio-to-text-with-chatgpt-and-notion/>Thomas Frank also wrote an article</a> on the subject and created several YouTube videos. He uses Pipedreams to push data into Notion, which is an interesting approach but more suited to Notion&rsquo;s web-based API system.</p><h2 id=my-current-solution>My Current Solution<a hidden class=anchor aria-hidden=true href=#my-current-solution>#</a></h2><p>To ease into audio journaling while keeping it simple, I&rsquo;ve devised the following workflow:</p><ol><li>Record a voice memo on my iPhone.</li><li>Share the recording via the Nextcloud app.</li><li>(The next morning) Process the audio file with OpenAI Whisper.</li><li>Run the transcript through a language model to correct names, remove filler words, and summarize the text into bullet points.</li><li>Copy and paste the results into Logseq.</li></ol><p>I&rsquo;ve consolidated the last three steps into a small shell script that processes the latest file, transcribes it, and runs it through a language model. The output is automatically copied to the clipboard, allowing me to simply press Control+V in Logseq.</p><h3 id=automating-transcription>Automating Transcription<a hidden class=anchor aria-hidden=true href=#automating-transcription>#</a></h3><p>OpenAI Whisper is open source and easy to install. On Arch Linux, you can set it up with <code>sudo pacman -S python-openai-whisper</code>. Running <code>whisper "New Recording.m4a" --language German</code> provides initial results. However, on my Thinkpad without a powerful graphics card, it takes quite a while.</p><p>For the impatient (like me), there&rsquo;s a paid API option:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl --request POST <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--url https://api.openai.com/v1/audio/transcriptions <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--header <span style=color:#e6db74>&#34;Authorization: Bearer </span>$OPENAI_API_KEY<span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--header <span style=color:#e6db74>&#39;Content-Type: multipart/form-data&#39;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--form file<span style=color:#f92672>=</span>@<span style=color:#e6db74>&#39;New Recording.m4a&#39;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>--form model<span style=color:#f92672>=</span>whisper-1 -F response_format<span style=color:#f92672>=</span>text -o out
</span></span></code></pre></div><p>In just a second or two, you get a transcript of your lengthy recording.</p><h3 id=summarizing-with-the-language-model>Summarizing with the Language Model<a hidden class=anchor aria-hidden=true href=#summarizing-with-the-language-model>#</a></h3><p>Now that we have a transcript, it&rsquo;s still more of a ramble than concise answers to my daily reflection questions. Software project names and peoples names might also be misspelled.</p><p>I&rsquo;ve come to appreciate the <a href=https://llm.datasette.io/en/stable/>Python module llm</a> as a CLI tool for interacting with language models. On Arch, it&rsquo;s conveniently installed with <code>python-pipx</code>. Simply run <code>pipx install llm</code>. Done.</p><p>The advantage of this tool is its ability to pipe files through standard input and abstract different language models. Whether using a local Llama model or one hosted on AWS Bedrock, Claude, or OpenAI, the command remains the same. You can also set a template with maximum token count, temperature, and system prompt.</p><p>Here&rsquo;s the command to use:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>llm --system <span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>cat system.txt<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span> -o max_tokens <span style=color:#ae81ff>4096</span> --save audio-journal
</span></span></code></pre></div><p>To trigger it, simply run:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>llm -t audio-journal &lt; out
</span></span></code></pre></div><div class="admonition note"><div class=admonition-icon>癸</div><div class=admonition-body><p><strong>System Prompt</strong></p><p>The system prompt is highly personal, but I&rsquo;m happy to share mine for inspiration (actually mine is in German language):</p><p>You are a helpful assistant preparing transcribed audio notes for a journal. The focus is on evening reflection questions. The journal is in German. Summarize the answers concisely using bullet points, but form complete sentences. Remove filler words and phrases. Each bullet point should start with <code>[[gpt]]</code>. If a bullet point is too long, split it into two or more points.</p><p>Correct misspelled project and product names.</p><p>Correct misspelled names of people. Add last names if I only mention the first name and it&rsquo;s clear. Names should also be enclosed in square brackets, e.g., [[Max Mustermann]].</p><p>Names of friends: XXX</p><p>Names of some colleagues: XXX</p><p>Nicknames: XXX is YYY, XXX is YYY. Replace nicknames with full names.</p><p>Names of software projects, etc., that might be mentioned: Logseq, Todoist, Claude, Chat-GPT, Deepseek, Llama, cadiff</p><p>Your response should be formatted as follows:</p><h2 id=evening-questions-daily>[[Evening Questions]] #daily<a hidden class=anchor aria-hidden=true href=#evening-questions-daily>#</a></h2><h3 id=how-am-i-feeling>[[How Am I feeling?]]<a hidden class=anchor aria-hidden=true href=#how-am-i-feeling>#</a></h3><ul><li>[[gpt]] Insert bullet points from transcript here</li><li>[[gpt]] Repeat line if necessary</li></ul><h3 id=whats-something-good-that-happened-today>[[Whats Something Good That Happened Today?]]<a hidden class=anchor aria-hidden=true href=#whats-something-good-that-happened-today>#</a></h3><ul><li>[[gpt]] Insert bullet points from transcript here</li><li>[[gpt]] Repeat line if necessary</li></ul><h3 id=what-did-i-do-well>[[What Did I Do Well?]]<a hidden class=anchor aria-hidden=true href=#what-did-i-do-well>#</a></h3><ul><li>[[gpt]] Insert bullet points from transcript here</li><li>[[gpt]] Repeat line if necessary</li></ul><h3 id=what-could-i-have-done-better>[[What Could I Have Done Better?]]<a hidden class=anchor aria-hidden=true href=#what-could-i-have-done-better>#</a></h3><ul><li>[[gpt]] Insert bullet points from transcript here</li><li>[[gpt]] Repeat line if necessary</li></ul><h3 id=what-am-i-thinking-of>[[What Am I Thinking of?]]<a hidden class=anchor aria-hidden=true href=#what-am-i-thinking-of>#</a></h3><ul><li>[[gpt]] Insert bullet points from transcript here</li><li>[[gpt]] Repeat line if necessary</li></ul></div></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://stefansiegl.de/tags/audio-journaling/>Audio Journaling</a></li><li><a href=https://stefansiegl.de/tags/whisper/>Whisper</a></li><li><a href=https://stefansiegl.de/tags/logseq/>Logseq</a></li></ul></footer></article></main><footer class=footer><span>漏 2025 Stefan Siegl 路 all content is <a href=https://creativecommons.org/licenses/by-sa/4.0/deed>CC-BY-SA</a> 路 <a href=https://www.swyx.io/digital-garden-tos#for-visitors>Terms of Service</a></span> 路
<a href=/imprint>Imprint</a> 路
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>